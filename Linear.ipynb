{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Lasso, Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Advertising.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop('Unnamed: 0',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = data[:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 4)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = new_data.drop('Sales', axis=1)\n",
    "y = new_data['Sales']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Use LinearRegression to predict the sales using cross-validation, interpret the results why cross_val score for testing is increasing/ decreasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train , X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaling the data\n",
    "scale = StandardScaler()\n",
    "sc = scale.fit(X_train)\n",
    "X_train = sc.transform(X_train)\n",
    "X_test = sc.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "linreg = LinearRegression()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.121539431218783"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv_5_results = np.mean(cross_val_score(linreg, X_train, y_train, cv=5, scoring=\"neg_mean_squared_error\"))\n",
    "cv_5_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-11.328598375446953"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_5_results = np.mean(cross_val_score(linreg, X_test, y_test, cv=5, scoring=\"neg_mean_squared_error\"))\n",
    "cv_5_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = linreg.predict(X_train)\n",
    "y_test_pred = linreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainingr2: 0.8696375446203377\n",
      "Testingr2: 0.8777492233281081\n"
     ]
    }
   ],
   "source": [
    "train_score = linreg.score(X_train, y_train)\n",
    "test_score = linreg.score(X_test, y_test)\n",
    "\n",
    "print('Trainingr2:',train_score )\n",
    "print('Testingr2:',test_score )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  2. Is it a Bias or Variance problem ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. What method would you use to solve overfitting / underfitting problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>TV^2</th>\n",
       "      <th>TV Radio</th>\n",
       "      <th>TV Newspaper</th>\n",
       "      <th>Radio^2</th>\n",
       "      <th>Radio Newspaper</th>\n",
       "      <th>Newspaper^2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.373697</td>\n",
       "      <td>-0.439923</td>\n",
       "      <td>0.173525</td>\n",
       "      <td>0.139650</td>\n",
       "      <td>0.164398</td>\n",
       "      <td>-0.064846</td>\n",
       "      <td>0.193532</td>\n",
       "      <td>-0.076338</td>\n",
       "      <td>0.030111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.892069</td>\n",
       "      <td>-0.473776</td>\n",
       "      <td>-0.337874</td>\n",
       "      <td>0.795788</td>\n",
       "      <td>-0.422641</td>\n",
       "      <td>-0.301407</td>\n",
       "      <td>0.224464</td>\n",
       "      <td>0.160077</td>\n",
       "      <td>0.114159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.545903</td>\n",
       "      <td>-1.516455</td>\n",
       "      <td>-0.181155</td>\n",
       "      <td>0.298010</td>\n",
       "      <td>0.827838</td>\n",
       "      <td>0.098893</td>\n",
       "      <td>2.299637</td>\n",
       "      <td>0.274714</td>\n",
       "      <td>0.032817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.271580</td>\n",
       "      <td>-1.381043</td>\n",
       "      <td>-0.614195</td>\n",
       "      <td>1.616915</td>\n",
       "      <td>-1.756106</td>\n",
       "      <td>-0.780998</td>\n",
       "      <td>1.907278</td>\n",
       "      <td>0.848229</td>\n",
       "      <td>0.377235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.049687</td>\n",
       "      <td>1.178262</td>\n",
       "      <td>0.994239</td>\n",
       "      <td>0.002469</td>\n",
       "      <td>0.058545</td>\n",
       "      <td>0.049401</td>\n",
       "      <td>1.388301</td>\n",
       "      <td>1.171474</td>\n",
       "      <td>0.988511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         TV     Radio  Newspaper      TV^2  TV Radio  TV Newspaper   Radio^2  \\\n",
       "0 -0.373697 -0.439923   0.173525  0.139650  0.164398     -0.064846  0.193532   \n",
       "1  0.892069 -0.473776  -0.337874  0.795788 -0.422641     -0.301407  0.224464   \n",
       "2 -0.545903 -1.516455  -0.181155  0.298010  0.827838      0.098893  2.299637   \n",
       "3  1.271580 -1.381043  -0.614195  1.616915 -1.756106     -0.780998  1.907278   \n",
       "4  0.049687  1.178262   0.994239  0.002469  0.058545      0.049401  1.388301   \n",
       "\n",
       "   Radio Newspaper  Newspaper^2  \n",
       "0        -0.076338     0.030111  \n",
       "1         0.160077     0.114159  \n",
       "2         0.274714     0.032817  \n",
       "3         0.848229     0.377235  \n",
       "4         1.171474     0.988511  "
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly = PolynomialFeatures(degree=2, interaction_only=False, include_bias=False)\n",
    "X_poly_train = pd.DataFrame(poly.fit_transform(X_train), columns=poly.get_feature_names(X.columns))\n",
    "X_poly_test = pd.DataFrame(poly.transform(X_test), columns=poly.get_feature_names(X.columns))\n",
    "X_poly_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_poly = LinearRegression()\n",
    "lr_poly.fit(X_poly_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training r2: 0.9896179697766543\n",
      "Testing r2: 0.9884186864149485\n"
     ]
    }
   ],
   "source": [
    "train_poly_score = lr_poly.score(X_poly_train, y_train)\n",
    "test_poly_score = lr_poly.score(X_poly_test, y_test)\n",
    "\n",
    "print('Training r2:', train_poly_score)\n",
    "print('Testing r2:', test_poly_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias=9.25185853854297e-18 and Variance=0.8542490208259486\n"
     ]
    }
   ],
   "source": [
    "b = bias(y_train, lr_poly.predict(X_poly_train)) #Your code here\n",
    "v = variance(lr_poly.predict(X_poly_train)) #Your code here\n",
    "print('Bias={} and Variance={}'.format(b,v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias=0.0212484900587654 and Variance=1.0385882507119764\n"
     ]
    }
   ],
   "source": [
    "b = bias(y_test, lr_poly.predict(X_poly_test)) #Your code here\n",
    "v = variance(lr_poly.predict(X_poly_test)) #Your code here\n",
    "print('Bias={} and Variance={}'.format(b,v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "k should be >=0, <= n_features = 3; got 9. Use k='all' to return all features.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-168-f7f68ea038a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbestfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSelectKBest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchi2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbestfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdfscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscores_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdfcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#concat two dataframes for better visualization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/feature_selection/univariate_selection.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    346\u001b[0m                             % (self.score_func, type(self.score_func)))\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m         \u001b[0mscore_func_ret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_func_ret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/feature_selection/univariate_selection.py\u001b[0m in \u001b[0;36m_check_params\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    512\u001b[0m             raise ValueError(\"k should be >=0, <= n_features = %d; got %r. \"\n\u001b[1;32m    513\u001b[0m                              \u001b[0;34m\"Use k='all' to return all features.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m                              % (X.shape[1], self.k))\n\u001b[0m\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_support_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: k should be >=0, <= n_features = 3; got 9. Use k='all' to return all features."
     ]
    }
   ],
   "source": [
    "bestfeatures = SelectKBest(score_func=chi2, k=9)\n",
    "fit = bestfeatures.fit(X,y)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(X.columns)\n",
    "#concat two dataframes for better visualization \n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "featureScores.columns = ['Specs','Score']  #naming the dataframe columns\n",
    "print(featureScores.nlargest(10,'Score'))  #print 10 best features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Use Regularization, Which is better Lasso / Ridge / Simple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training r2: 0.8552719299169915\n",
      "Testing r2: 0.8207648921282686\n"
     ]
    }
   ],
   "source": [
    "lasso = Lasso(alpha=.05) \n",
    "lasso.fit(X_train, y_train)\n",
    "print('Training r2:', lasso.score(X_train, y_train))\n",
    "print('Testing r2:', lasso.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training r2: 0.8682322326931468\n",
      "Testing r2: 0.8627751872621978\n"
     ]
    }
   ],
   "source": [
    "ridge = Ridge() #Lasso is also known as the L1 norm.\n",
    "ridge.fit(X_train, y_train)\n",
    "print('Training r2:', ridge.score(X_train, y_train))\n",
    "print('Testing r2:', ridge.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
